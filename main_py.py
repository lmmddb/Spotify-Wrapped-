# -*- coding: utf-8 -*-
"""main.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kIX8jR7CGhDMfYdfkeZJXbbeZ_u9ITTx
"""

#LIBRAIRIES
!pip install spotipy
import os
import json
import pandas as pd
import spotipy
from spotipy.oauth2 import SpotifyClientCredentials

# IMPORT DATA - Compatible Drive et Upload Local avec menu interactif
import os
import json
import pandas as pd
from google.colab import drive, files
import ipywidgets as widgets
from IPython.display import display, clear_output

def load_spotify_files(source='drive', folder_path=None, pattern="StreamingHistory_music_"):
    """
    Charge les fichiers Spotify depuis Google Drive ou upload local

    Args:
        source: 'drive' ou 'upload'
        folder_path: chemin du dossier Drive (si source='drive')
        pattern: pr√©fixe des fichiers √† charger
    """
    dataframes = []

    if source == 'drive':
        # Montage de Google Drive
        drive.mount('/content/drive')

        if folder_path is None:
            folder_path = '/content/drive/MyDrive/Spotify'

        try:
            files_list = [f for f in os.listdir(folder_path)
                         if f.startswith(pattern) and f.endswith(".json")]

            for filename in sorted(files_list):
                file_path = os.path.join(folder_path, filename)
                try:
                    with open(file_path, 'r', encoding='utf-8') as file:
                        data = json.load(file)
                        df = pd.json_normalize(data)
                        dataframes.append(df)
                        print(f"‚úì {filename} charg√© ({len(df)} lignes)")
                except json.JSONDecodeError as e:
                    print(f"‚úó Erreur dans {filename}: {e}")

        except FileNotFoundError:
            print(f"‚ùå Dossier '{folder_path}' introuvable")
            return pd.DataFrame()

    elif source == 'upload':
        # Upload de fichiers locaux
        print("üìÅ S√©lectionnez vos fichiers JSON Spotify...")
        uploaded = files.upload()

        for filename in sorted(uploaded.keys()):
            if filename.startswith(pattern) and filename.endswith(".json"):
                try:
                    # √âcrire le fichier upload√© sur le syst√®me de fichiers Colab
                    with open(filename, 'wb') as f:
                        f.write(uploaded[filename])

                    # Lire et parser le JSON
                    with open(filename, 'r', encoding='utf-8') as file:
                        data = json.load(file)
                        df = pd.json_normalize(data)
                        dataframes.append(df)
                        print(f"‚úì {filename} charg√© ({len(df)} lignes)")
                except json.JSONDecodeError as e:
                    print(f"‚úó Erreur dans {filename}: {e}")
            else:
                print(f"‚ö†Ô∏è {filename} ignor√© (ne correspond pas au pattern)")

    else:
        print(f"‚ùå Source '{source}' invalide. Utilisez 'drive' ou 'upload'")
        return pd.DataFrame()

    # Combiner tous les DataFrames
    if dataframes:
        combined = pd.concat(dataframes, ignore_index=True)
        print(f"\nüìä Total: {len(combined)} enregistrements")
        return combined
    else:
        print("‚ö†Ô∏è Aucun fichier charg√©")
        return pd.DataFrame()


# INTERFACE INTERACTIVE
output = widgets.Output()
streaming = None

# Menu d√©roulant
source_dropdown = widgets.Dropdown(
    options=[
        ('üìÅ Google Drive', 'drive'),
        ('üíæ Upload local', 'upload')
    ],
    value='drive',
    description='Source :',
    style={'description_width': 'initial'}
)

# Champ pour le chemin Drive
path_input = widgets.Text(
    value='/content/drive/MyDrive/Spotify',
    description='Chemin Drive :',
    style={'description_width': 'initial'},
    layout=widgets.Layout(width='400px')
)

# Bouton de chargement
load_button = widgets.Button(
    description='üì• Charger les donn√©es',
    button_style='success',
    tooltip='Cliquez pour charger les fichiers',
    icon='check'
)

# Fonction de chargement
def on_load_button_clicked(b):
    global streaming
    with output:
        clear_output()
        source = source_dropdown.value

        if source == 'drive':
            streaming = load_spotify_files(
                source='drive',
                folder_path=path_input.value
            )
        else:
            streaming = load_spotify_files(source='upload')

        if not streaming.empty:
            print("\n" + "="*50)
            print("APER√áU DES DONN√âES :")
            print("="*50)
            display(streaming.head())

load_button.on_click(on_load_button_clicked)

# Affichage de l'interface
def show_interface():
    # Afficher ou masquer le champ path selon la source
    def on_source_change(change):
        if change['new'] == 'drive':
            path_input.layout.display = 'flex'
        else:
            path_input.layout.display = 'none'

    source_dropdown.observe(on_source_change, names='value')

    # Interface
    interface = widgets.VBox([
        widgets.HTML("<h3>üéµ Chargement des donn√©es Spotify</h3>"),
        source_dropdown,
        path_input,
        load_button,
        output
    ])

    display(interface)

# Lancer l'interface
show_interface()

#CLEAN AND PREPA DATA
#Le but est de s√©lectionner des donn√©es pertinentes, √† savoir des donn√©es concernant l'ann√©e 2025 uniquement,
#des musiques que j'ai r√©ellement √©couter donc les musiques zapp√©es ne seront pas utilis√©es
#et essayer de nettoyer au mieux les musiques du type lofi/white noise/rain

#convert to datetime format
streaming["endTime"] = pd.to_datetime(streaming["endTime"])

#filter for only 2025
streaming_2025_df = streaming[streaming["endTime"].dt.year == 2025]

# D√©finir le seuil (ajustez selon votre analyse)
threshold = 15  # en secondes

# Calculer la dur√©e en secondes si pas d√©j√† fait
streaming['seconds_played'] = streaming_2025_df['msPlayed'] / 1000

# Filtrer : garder seulement les √©coutes >= seuil
streaming = streaming_2025_df[streaming['seconds_played'] >= threshold].copy()

print(f"‚úì √âcoutes de moins de {threshold}s supprim√©es")
print(f"üìä {len(streaming)} √©coutes restantes")
###########################################

# D√©tecter les potentiels sons d'ambiance
keywords_to_check = [
    'rain', 'thunder', 'storm', 'ocean', 'wave', 'water', 'river', 'stream',
    'nature', 'forest', 'bird', 'wind', 'fire', 'crackling',
    'white noise', 'pink noise', 'brown noise', 'ambient noise',
    'asmr', 'binaural', 'meditation', 'relaxation', 'calm', 'peace',
    'yoga', 'zen', 'chakra', 'mindfulness', 'sleep', 'sleeping',
    'healing', 'therapy', 'spa', 'massage',
    'lofi', 'lo-fi', 'lo fi', 'chill beats', 'study beats',
    'frequency', 'hz', 'hertz', 'tone', 'soundscape'
]

def detect_ambient(row):
    text = f"{row.get('trackName', '')} {row.get('artistName', '')}".lower()
    return any(keyword in text for keyword in keywords_to_check)

# Marquer les suspects
streaming['is_suspect'] = streaming.apply(detect_ambient, axis=1)

# Cr√©er la liste des suspects avec leurs stats
suspects = streaming[streaming['is_suspect']].groupby(['trackName', 'artistName']).agg({
    'msPlayed': ['count', 'sum']
}).reset_index()

suspects.columns = ['trackName', 'artistName', 'nb_ecoutes', 'temps_total_ms']
suspects['temps_total_min'] = suspects['temps_total_ms'] / 60000
suspects = suspects.sort_values('nb_ecoutes', ascending=False)

print(f"üîç {len(suspects)} pistes suspectes d√©tect√©es\n")
print("="*80)
display(suspects)

# Cr√©er un fichier CSV pour faciliter la s√©lection
suspects.to_csv('/content/drive/MyDrive/Spotify/suspects_to_review.csv', index=False)
print("\nüíæ Liste export√©e dans: suspects_to_review.csv")
print("üìù Instructions:")
print("   1. Ouvrez le fichier CSV")
print("   2. Ajoutez une colonne 'supprimer' avec 'oui' ou 'non'")
print("   3. Sauvegardez et r√©ex√©cutez la cellule suivante")

# Charger vos choix
choix = pd.read_csv('/content/drive/MyDrive/Spotify/suspects_to_review1.csv')

# V√©rifier si la colonne existe
if 'supprimer' not in choix.columns:
    print("‚ùå Ajoutez d'abord une colonne 'supprimer' dans le CSV avec 'oui' ou 'non'")
else:
    # Filtrer ce qui doit √™tre supprim√©
    to_remove = choix[choix['supprimer'].str.lower() == 'oui'][['trackName', 'artistName']]

    print(f"üóëÔ∏è {len(to_remove)} pistes uniques √† supprimer:")
    display(to_remove)

    # Cr√©er un identifiant unique pour matcher
    streaming['track_id'] = streaming['trackName'] + '|||' + streaming['artistName']
    to_remove['track_id'] = to_remove['trackName'] + '|||' + to_remove['artistName']

    # Supprimer
    before = len(streaming)
    streaming = streaming[~streaming['track_id'].isin(to_remove['track_id'])].copy()
    after = len(streaming)

    # Nettoyer
    streaming.drop(['is_suspect', 'track_id'], axis=1, inplace=True)

    print(f"\n‚úÖ Suppression effectu√©e:")
    print(f"   Avant: {before} √©coutes")
    print(f"   Apr√®s: {after} √©coutes")
    print(f"   Supprim√©es: {before - after} √©coutes")

#STATISTIQUES TEMPORELLES
#Temps total d'√©coute en 2025
total_time_listening = streaming.msPlayed.sum() / 3600000
print(total_time_listening)

#Plage temporelle de l'ensemble de donn√©es
streaming.endTime.min(), streaming.endTime.max()

#moyenne de ms jou√©es chaque jour au cours de l'ann√©e (jusqu'au 05/12)
year_ms = streaming.msPlayed.sum() / (pd.Timestamp(streaming.endTime.max()) - pd.Timestamp(streaming.endTime.min())).days

#minutes par jour
avg_mins_day = year_ms / 60000

#heures par jour
avg_hours_day = year_ms / 3600000
print(avg_hours_day)

#Regardez les √©coutes mensuelles
streaming['month'] = streaming['endTime'].dt.month # Create 'month' column
monthly_listening = streaming.groupby("month")["msPlayed"].sum().reset_index()
monthly_listening["hours_listened"] =  monthly_listening["msPlayed"] / 3600000
monthly_listening.sort_values("hours_listened", ascending=False)

#ajouter une heure de la journ√©e
streaming['hour'] = streaming.endTime.dt.hour

#d√©finir des plages horaires pour l'√©coute horaire
def time_bucket(hour):
    if 3 <= hour < 11:
        return 'Morning'
    elif 11 <= hour < 18:
        return 'Afternoon'
    else:
        return 'Night'

#fonction d'application
streaming['time_bucket'] = streaming['hour'].apply(time_bucket)

#r√©sultats agr√©g√©s pour analyser l'heure d'√©coute
daily_listening = streaming.groupby("time_bucket")["msPlayed"].sum().reset_index()
daily_listening["hours_listened"] =  daily_listening["msPlayed"] / 3600000
daily_listening.sort_values("hours_listened", ascending=False)
daily_listening["percentage of time over year listening"] = (daily_listening["hours_listened"]/total_time_listening)*100

#Regardez l'√©coute horaire
hour_listening = streaming.groupby("hour")["msPlayed"].sum().reset_index()
hour_listening["hours_listened"] =  hour_listening["msPlayed"] / 3600000
hour_listening.sort_values("hours_listened", ascending=False)

# R√©cup√©rer les dur√©es des chansons et les genres
#CODE QUI MARCHE !!!!!!!!!!!!!!!!
# Utilisation de lastfm API

import requests
import time
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed


LASTFM_API_KEY = '83100e2042c7a645ac9b98747ec29b76'

def get_artist_genres_lastfm(artist_name):
    """R√©cup√®re les genres d'un artiste via Last.fm API"""
    url = "http://ws.audioscrobbler.com/2.0/"
    params = {
        'method': 'artist.gettoptags',
        'artist': artist_name,
        'api_key': LASTFM_API_KEY,
        'format': 'json'
    }

    try:
        response = requests.get(url, params=params, timeout=5)
        data = response.json()
        time.sleep(0.2) # Add a small delay to respect rate limits

        if 'toptags' in data and 'tag' in data['toptags']:
            genres = [tag['name'] for tag in data['toptags']['tag'][:3]]
            return artist_name, genres
        return artist_name, []
    except Exception as e:
        # print(f"DEBUG (Genres): Error for artist {artist_name}: {e}") # Uncomment for verbose debugging
        return artist_name, []

def get_track_album_lastfm(track_name, artist_name):
    """R√©cup√®re l'album avec plusieurs tentatives"""

    url = "http://ws.audioscrobbler.com/2.0/"

    # TENTATIVE 1 : track.getInfo
    params1 = {
        'method': 'track.getInfo',
        'artist': artist_name,
        'track': track_name,
        'api_key': LASTFM_API_KEY,
        'format': 'json'
    }
    try:
        response1 = requests.get(url, params=params1, timeout=5)
        data1 = response1.json()
        time.sleep(0.2) # Add a small delay to respect rate limits

        if 'track' in data1 and 'album' in data1['track']:
            album_name = data1['track']['album']['title']
            return (track_name, artist_name), album_name
    except:
        pass

    # TENTATIVE 2 : artist.getTopAlbums + recherche intelligente
    try:
        params2 = {
            'method': 'artist.gettopalbums',
            'artist': artist_name,
            'api_key': LASTFM_API_KEY,
            'format': 'json',
            'limit': 10
        }

        response2 = requests.get(url, params=params2, timeout=5)
        data2 = response2.json()
        time.sleep(0.2) # Add a small delay to respect rate limits

        if 'topalbums' in data2 and 'album' in data2['topalbums']:
            albums = data2['topalbums']['album']

            # Si on a des albums, prendre le plus populaire (premier)
            if albums and len(albums) > 0:
                return (track_name, artist_name), albums[0]['name']
    except:
        pass

    # TENTATIVE 3 : track.search (recherche floue)
    try:
        params3 = {
            'method': 'track.search',
            'track': track_name,
            'artist': artist_name,
            'api_key': LASTFM_API_KEY,
            'format': 'json',
            'limit': 1
        }

        response3 = requests.get(url, params=params3, timeout=5)
        data3 = response3.json()
        time.sleep(0.2) # Add a small delay to respect rate limits

        if 'results' in data3 and 'trackmatches' in data3['results']:
            tracks = data3['results']['trackmatches'].get('track', [])
            if tracks:
                # Prendre le premier r√©sultat
                first_track = tracks[0] if isinstance(tracks, list) else tracks
                # Maintenant r√©cup√©rer les infos d√©taill√©es de cette chanson
                params4 = {
                    'method': 'track.getInfo',
                    'artist': first_track.get('artist', artist_name),
                    'track': first_track.get('name', track_name),
                    'api_key': LASTFM_API_KEY,
                    'format': 'json'
                }
                response4 = requests.get(url, params=params4, timeout=5)
                data4 = response4.json()
                time.sleep(0.2) # Add a small delay to respect rate limits

                if 'track' in data4 and 'album' in data4['track']:
                    return (track_name, artist_name), data4['track']['album']['title']
    except:
      pass

    return (track_name, artist_name), None

# √âTAPE 1 : R√©cup√©ration en parall√®le des genres
unique_artists = [a for a in streaming['artistName'].unique() if pd.notna(a)]
artist_genres_dict = {}

print(f"Traitement de {len(unique_artists)} artistes en parall√®le...")

with ThreadPoolExecutor(max_workers=10) as executor:
    futures = {executor.submit(get_artist_genres_lastfm, artist): artist for artist in unique_artists}

    for i, future in enumerate(as_completed(futures)):
        artist_name, genres = future.result()
        artist_genres_dict[artist_name] = genres

        if (i + 1) % 50 == 0:
            print(f"Progression: {i+1}/{len(unique_artists)}")

print("Genres termin√©s!")

# √âTAPE 2 : Pr√©parer les donn√©es
streaming['duration_calculated'] = streaming.groupby(
    ['trackName', 'artistName']
)['msPlayed'].transform('mean')

top_time_listened_songs = streaming.groupby(
    ["trackName",
     "artistName"]
).agg({
    'msPlayed': 'sum',
    'duration_calculated': 'first'
}).reset_index().sort_values('msPlayed', ascending=False)

# √âTAPE 3 : R√©cup√©ration des albums pour les top 500 chansons
top_songs_subset = top_time_listened_songs.head(500)
unique_tracks = [(row['trackName'], row['artistName']) for _, row in top_songs_subset.iterrows()
                 if pd.notna(row['trackName']) and pd.notna(row['artistName'])]

track_album_dict = {}

print(f"\nTraitement de {len(unique_tracks)} chansons pour les albums en parall√®le...")

with ThreadPoolExecutor(max_workers=5) as executor:
    futures = {executor.submit(get_track_album_lastfm, track, artist): (track, artist)
               for track, artist in unique_tracks}

    for i, future in enumerate(as_completed(futures)):
        track_artist_key, album_name = future.result()
        track_album_dict[track_artist_key] = album_name

        if (i + 1) % 50 == 0:
            print(f"Progression: {i+1}/{len(unique_tracks)}")

print("Albums termin√©s!")

# √âTAPE 4 : Ajouter les genres et albums
top_time_listened_songs['Genres'] = top_time_listened_songs['artistName'].map(artist_genres_dict)

def get_album_for_track(row):
    key = (row['trackName'], row['artistName'])
    return track_album_dict.get(key, None)

top_time_listened_songs['Album Name'] = top_time_listened_songs.apply(get_album_for_track, axis=1)

# Renommer les colonnes
songs_times_df = top_time_listened_songs.rename(columns={
    'trackName': 'Song Name',
    'artistName': 'Artist Name',
    'duration_calculated': 'Duration (ms)'
})

# Calculer le nombre approximatif d'√©coutes
songs_times_df["No. of times listened"] = songs_times_df["msPlayed"] / songs_times_df["Duration (ms)"]

# Trier par nombre d'√©coutes
top_songs_by_avg_listens = songs_times_df.sort_values("No. of times listened", ascending=False)

# TOP 10 SONGS
top_10_songs = top_songs_by_avg_listens[['Song Name', 'Artist Name', 'No. of times listened']].head(10)

# TOP 10 ARTISTS
top_artists = top_songs_by_avg_listens.groupby(["Artist Name"])["No. of times listened"].sum().sort_values(ascending=False).reset_index().head(10)

# TOP 10 ALBUMS
songs_with_albums = top_songs_by_avg_listens[top_songs_by_avg_listens['Album Name'].notna()].copy() # Filter for non-NA albums

if len(songs_with_albums) > 0:
    top_albums = songs_with_albums.groupby([
        "Album Name",
        "Artist Name"
    ])["No. of times listened"].sum().sort_values(ascending=False).reset_index().head(10)
else:
    print("\nAucun album trouv√©. V√©rifiez votre cl√© API Last.fm et la disponibilit√© des donn√©es pour ces titres.")
    top_albums = pd.DataFrame(columns=["Album Name", "Artist Name", "No. of times listened"])

# TOP 10 GENRES - AVEC NORMALISATION ET D√âDOUBLONNAGE
songs_with_genres = top_songs_by_avg_listens[top_songs_by_avg_listens['Genres'].notna()].copy()

# Ensure 'Genres' column contains lists, replace non-list with empty list to prevent errors during explode
songs_with_genres['Genres'] = songs_with_genres['Genres'].apply(lambda x: x if isinstance(x, list) else [])

songs_times_exploded = songs_with_genres.explode('Genres')

# Filtrer les valeurs None/NaN apr√®s l'explode et normaliser
songs_times_exploded = songs_times_exploded[songs_times_exploded['Genres'].notna()].copy()

if not songs_times_exploded.empty:
    songs_times_exploded['Genres_normalized'] = songs_times_exploded['Genres'].astype(str).str.lower().str.strip()

    # Mapping pour fusionner les genres similaires (ajust√© pour couvrir plus de cas)
    genre_mapping = {
        'rap': 'rap', 'hip hop': 'rap', 'hip-hop': 'rap', 'rap francais': 'rap', 'french rap': 'rap', 'trap': 'rap',
        'pop': 'pop', 'pop music': 'pop', 'electropop': 'pop', 'dance pop': 'pop', 'synth pop': 'pop',
        'rock': 'rock', 'alternative rock': 'rock', 'indie rock': 'rock', 'hard rock': 'rock',
        'r&b': 'r&b', 'rnb': 'r&b', 'rhythm and blues': 'r&b',
        'electronic': 'electronic', 'electro': 'electronic', 'edm': 'electronic', 'techno': 'electronic', 'house': 'electronic',
        'indie': 'indie', 'indie pop': 'indie', 'alternative': 'alternative',
        'soul': 'soul', 'funk': 'funk', 'jazz': 'jazz', 'metal': 'metal', 'heavy metal': 'metal',
        'country': 'country', 'folk': 'folk', 'reggae': 'reggae', 'blues': 'blues', 'classical': 'classical',
        'france': 'french', 'french hip hop': 'french rap', 'nigeria': 'afrobeats', 'african': 'afrobeats', 'congo': 'soukous',
        'afrobeat': 'afrobeats', 'gospel': 'religious', 'world': 'world music', 'hip-hop': 'hip hop', 'rhythm and blues': 'r&b'
    }

    # Appliquer le mapping
    songs_times_exploded['Genres_cleaned'] = songs_times_exploded['Genres_normalized'].map(
        lambda x: genre_mapping.get(x, x)
    )

    # Grouper par genre nettoy√©
    top_genres = songs_times_exploded.groupby("Genres_cleaned")["No. of times listened"].sum().sort_values(ascending=False).reset_index().head(10)
    top_genres.columns = ["Genre", "Total Listens"]

    # Capitaliser les genres pour l'affichage
    top_genres['Genre'] = top_genres['Genre'].str.title()
else:
    top_genres = pd.DataFrame(columns=["Genre", "Total Listens"])

# Afficher les r√©sultats
print("\n" + "="*50)
print("=== TOP 10 SONGS ===")
print("="*50)
print(top_10_songs.to_string(index=False))

print("\n" + "="*50)
print("=== TOP 10 ARTISTS ===")
print("="*50)
print(top_artists.to_string(index=False))

print("\n" + "="*50)
print("=== TOP 10 ALBUMS ===")
print("="*50)
if not top_albums.empty:
    print(top_albums.to_string(index=False))
else:
    print("Aucun album trouv√©. V√©rifiez votre cl√© API Last.fm et la disponibilit√© des donn√©es pour ces titres.")

print("\n" + "="*50)
print("=== TOP 10 GENRES ===")
print("="*50)
print(top_genres.to_string(index=False))

# Statistiques de couverture
coverage_genres = (songs_with_genres["No. of times listened"].sum() / songs_times_df["No. of times listened"].sum()) * 100
coverage_albums = (songs_with_albums["No. of times listened"].sum() / songs_times_df["No. of times listened"].sum()) * 100 if not songs_with_albums.empty else 0

print(f"\nüìä Couverture des genres : {coverage_genres:.1f}% de vos √©coutes totales")
print(f"üìÄ Albums trouv√©s : {len(songs_with_albums)} chansons ({coverage_albums:.1f}% de vos √©coutes)")

